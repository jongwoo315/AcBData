---
layout: post
title: Python - 17/03/07 (4)
category: acorn수업
---

# 유클리디안 거리, 내적, iris scatter

---
원래 ipynb 제목  
3_1 knn_정리.ipynb  

교재: Building Machine Learning Systems  
데이터: 31p  
내용: 43p  

## <font color='crimson'>Nearest neighbor classification

1. when classifying a new element
- it looks at the training data for the object that is closest to it(nearest neighbor)
- and return its label as the answer  

###### performs perfectly on its training data  
###### it is essential to test the classification using cross-validation protocol  

- fit(features, labels): this is the learning step and fits the parameters of the model
- predict(features): this method can only be called after fit and returns a prediction for one or more inputs  

<font color='coral'>load iris data  

```python
from sklearn.datasets import load_iris
data = load_iris()
```

<br>

```python
features = data.data
```

<br>

```python
feature_names = data.feature_names
```

<br>

```python
# species into numeric
target = data.target
len(target)
```




    150


<br>

```python
# species
target_names = data.target_names
target_names
```




    array(['setosa', 'versicolor', 'virginica'],
          dtype='|S10')


<br>

```python
labels = target_names[target]
labels[48:55]
```




    array(['setosa', 'setosa', 'versicolor', 'versicolor', 'versicolor',
           'versicolor', 'versicolor'],
          dtype='|S10')

<br>

<font color='coral'>specify the number of neighbors to consider  

```python
# sk = SciKit
from sklearn.neighbors import KNeighborsClassifier
```

<br>

```python
# 매개변수를 지정하지 않으면 이웃은 5로 지정됨
classifier = KNeighborsClassifier(n_neighbors=1)
```

<br>

<font color='coral'>use cross-validation(of course) to look at our data


```python
from sklearn.cross_validation import KFold
# cross_validation will be deprecated

##from sklearn.model_selection import KFold #이것도 아님
```

    /usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
      "This module will be removed in 0.20.", DeprecationWarning)

<br>

```python
import numpy as np
```

<br>

```python
# features => 꽃받침, 꽃잎에 대한 데이터
kf = KFold(len(features), n_folds=5, shuffle=True)
means = []
for training, testing in kf:
    # we fit a model for this fold,
    # then apply it to test data with predict
    classifier.fit(features[training], labels[training])
    prediction = classifier.predict(features[testing])

    # np.mean on an array of booleans
    # returns fraction of correct decisions for this fold:
    curmean = np.mean(prediction == labels[testing])
    means.append(curmean)

print '{:.1%}'.format(np.mean(means))
```

    96.0%

<br>

<font color='coral'>Using five folds for cross-validation with this algorithm, we obtain 96 percent accuracy.  
<font color='coral'>As we discussed in the earlier section, the cross-validation accuracy is lower than the training accuracy,  
<font color='coral'>but this is a more credible estimate of the performance of the model.  
