---
layout: post
title: Python - 17/03/06 (4)
category: acorn수업
---

# 회귀분석

---

원래 ipynb 제목
3. regression_questions.ipynb

<br>

1. housing data를 이용해 다음 과정을 실시하시오.
    - 데이터 로딩
    - 데이터 컬럼 확인
    - LSTAT, INDUS, NOX, RM, MEDV의 상호 상관그래프를 출력하고 heatmap으로도 출력
    - X = RM: 방의 갯수, y = MEDV: 집값
    - 데이터 분산도(산포도?)를 출력
    - train data와 test데이터로 분리 (train_test_split 사용)
    - Linear Regression / Lasso / Ridge / elastic Net 방식으로 선형회귀 분석을 실시한 다음 계수를 출력하고 비교 그래프 출력
    - 선형 회귀선을 출력
    - Ridge 회귀 분석에서 적절한 alpha값을 결정
    - 각 분석방법에 대하여 r2_score로 평가하고 mean_squared_error를 이용하여 MSE값을 출력

<br>

## <font color='orange'/>데이터 로딩, 데이터 컬럼 확인


```python
import pandas as pd
pd.DataFrame(boston.data, columns=boston.feature_names)
```

<br>

```python
from sklearn import datasets
```

<br>

```python
boston = datasets.load_boston()
```

<br>

```python
bost = pd.DataFrame(boston.data, columns=boston.feature_names)
```

<br>

```python
boston.DESCR.split('\n')
```




    ['Boston House Prices dataset',
     '===========================',
     '',
     'Notes',
     '------',
     'Data Set Characteristics:  ',
     '',
     '    :Number of Instances: 506 ',
     '',
     '    :Number of Attributes: 13 numeric/categorical predictive',
     '    ',
     '    :Median Value (attribute 14) is usually the target',
     '',
     '    :Attribute Information (in order):',
     '        - CRIM     per capita crime rate by town',
     '        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.',
     '        - INDUS    proportion of non-retail business acres per town',
     '        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)',
     '        - NOX      nitric oxides concentration (parts per 10 million)',
     '        - RM       average number of rooms per dwelling',
     '        - AGE      proportion of owner-occupied units built prior to 1940',
     '        - DIS      weighted distances to five Boston employment centres',
     '        - RAD      index of accessibility to radial highways',
     '        - TAX      full-value property-tax rate per $10,000',
     '        - PTRATIO  pupil-teacher ratio by town',
     '        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town',
     '        - LSTAT    % lower status of the population',
     "        - MEDV     Median value of owner-occupied homes in $1000's",
     '',
     '    :Missing Attribute Values: None',
     '',
     '    :Creator: Harrison, D. and Rubinfeld, D.L.',
     '',
     'This is a copy of UCI ML housing dataset.',
     'http://archive.ics.uci.edu/ml/datasets/Housing',
     '',
     '',
     'This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.',
     '',
     "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic",
     "prices and the demand for clean air', J. Environ. Economics & Management,",
     "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics",
     "...', Wiley, 1980.   N.B. Various transformations are used in the table on",
     'pages 244-261 of the latter.',
     '',
     'The Boston house-price data has been used in many machine learning papers that address regression',
     'problems.   ',
     '     ',
     '**References**',
     '',
     "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.",
     '   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.',
     '   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)',
     '']

<br>

['Boston House Prices dataset']  

'Data Set Characteristics  
- Number of Instances: 506
- Number of Attributes: 13 numeric/categorical predictive'
- Median Value (attribute 14) is usually the target'
- Attribute Information (in order):'
    - CRIM     per capita crime rate by town'
    - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.'
    - INDUS    proportion of non-retail business acres per town'
    - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)'
    - NOX      nitric oxides concentration (parts per 10 million)'
    - RM       average number of rooms per dwelling'
    - AGE      proportion of owner-occupied units built prior to 1940'
    - DIS      weighted distances to five Boston employment centres'
    - RAD      index of accessibility to radial highways'
    - TAX      full-value property-tax rate per $10,000'
    - PTRATIO  pupil-teacher ratio by town'
    - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town'
    - LSTAT    % lower status of the population'
    - MEDV     Median value of owner-occupied homes in $1000's"

- Missing Attribute Values: None'

<br>

```python
bosto = pd.read_table('housing.data', header=None, delimiter='\s+')
```

<br>

```python
bosto.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>10</th>
      <th>11</th>
      <th>12</th>
      <th>13</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.00632</td>
      <td>18</td>
      <td>2.31</td>
      <td>0</td>
      <td>0.538</td>
      <td>6.575</td>
      <td>65.2</td>
      <td>4.0900</td>
      <td>1</td>
      <td>296</td>
      <td>15.3</td>
      <td>396.90</td>
      <td>4.98</td>
      <td>24.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.02731</td>
      <td>0</td>
      <td>7.07</td>
      <td>0</td>
      <td>0.469</td>
      <td>6.421</td>
      <td>78.9</td>
      <td>4.9671</td>
      <td>2</td>
      <td>242</td>
      <td>17.8</td>
      <td>396.90</td>
      <td>9.14</td>
      <td>21.6</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.02729</td>
      <td>0</td>
      <td>7.07</td>
      <td>0</td>
      <td>0.469</td>
      <td>7.185</td>
      <td>61.1</td>
      <td>4.9671</td>
      <td>2</td>
      <td>242</td>
      <td>17.8</td>
      <td>392.83</td>
      <td>4.03</td>
      <td>34.7</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.03237</td>
      <td>0</td>
      <td>2.18</td>
      <td>0</td>
      <td>0.458</td>
      <td>6.998</td>
      <td>45.8</td>
      <td>6.0622</td>
      <td>3</td>
      <td>222</td>
      <td>18.7</td>
      <td>394.63</td>
      <td>2.94</td>
      <td>33.4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.06905</td>
      <td>0</td>
      <td>2.18</td>
      <td>0</td>
      <td>0.458</td>
      <td>7.147</td>
      <td>54.2</td>
      <td>6.0622</td>
      <td>3</td>
      <td>222</td>
      <td>18.7</td>
      <td>396.90</td>
      <td>5.33</td>
      <td>36.2</td>
    </tr>
  </tbody>
</table>
</div>


<br>

```python
cols = pd.Series(boston.feature_names)
cols = cols.append(pd.Series('MEDV'))
cols
```




    0        CRIM
    1          ZN
    2       INDUS
    3        CHAS
    4         NOX
    5          RM
    6         AGE
    7         DIS
    8         RAD
    9         TAX
    10    PTRATIO
    11          B
    12      LSTAT
    0        MEDV
    dtype: object


<br>

```python
bosto.columns = cols
```

<br>

```python
bosto.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CRIM</th>
      <th>ZN</th>
      <th>INDUS</th>
      <th>CHAS</th>
      <th>NOX</th>
      <th>RM</th>
      <th>AGE</th>
      <th>DIS</th>
      <th>RAD</th>
      <th>TAX</th>
      <th>PTRATIO</th>
      <th>B</th>
      <th>LSTAT</th>
      <th>MEDV</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.00632</td>
      <td>18</td>
      <td>2.31</td>
      <td>0</td>
      <td>0.538</td>
      <td>6.575</td>
      <td>65.2</td>
      <td>4.0900</td>
      <td>1</td>
      <td>296</td>
      <td>15.3</td>
      <td>396.90</td>
      <td>4.98</td>
      <td>24.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.02731</td>
      <td>0</td>
      <td>7.07</td>
      <td>0</td>
      <td>0.469</td>
      <td>6.421</td>
      <td>78.9</td>
      <td>4.9671</td>
      <td>2</td>
      <td>242</td>
      <td>17.8</td>
      <td>396.90</td>
      <td>9.14</td>
      <td>21.6</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.02729</td>
      <td>0</td>
      <td>7.07</td>
      <td>0</td>
      <td>0.469</td>
      <td>7.185</td>
      <td>61.1</td>
      <td>4.9671</td>
      <td>2</td>
      <td>242</td>
      <td>17.8</td>
      <td>392.83</td>
      <td>4.03</td>
      <td>34.7</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.03237</td>
      <td>0</td>
      <td>2.18</td>
      <td>0</td>
      <td>0.458</td>
      <td>6.998</td>
      <td>45.8</td>
      <td>6.0622</td>
      <td>3</td>
      <td>222</td>
      <td>18.7</td>
      <td>394.63</td>
      <td>2.94</td>
      <td>33.4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.06905</td>
      <td>0</td>
      <td>2.18</td>
      <td>0</td>
      <td>0.458</td>
      <td>7.147</td>
      <td>54.2</td>
      <td>6.0622</td>
      <td>3</td>
      <td>222</td>
      <td>18.7</td>
      <td>396.90</td>
      <td>5.33</td>
      <td>36.2</td>
    </tr>
  </tbody>
</table>
</div>

<br>

## <font color='orange'> LSTAT, INDUS, NOX, RM, MEDV의 상호 상관그래프를 출력하고 heatmap으로도 출력


```python
import matplotlib.pyplot as plt
%matplotlib inline
```

<br>

```python
bost1 = pd.DataFrame([bosto.LSTAT, bosto.INDUS, bosto.NOX, bosto.RM, bosto.MEDV], index=['LSTAT', 'INDUS', 'NOX', 'RM', 'MEDV'])
```

<br>

```python
bost1 = bost1.T
```

<br>

```python
bost1[:6]
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>LSTAT</th>
      <th>INDUS</th>
      <th>NOX</th>
      <th>RM</th>
      <th>MEDV</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>4.98</td>
      <td>2.31</td>
      <td>0.538</td>
      <td>6.575</td>
      <td>24.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>9.14</td>
      <td>7.07</td>
      <td>0.469</td>
      <td>6.421</td>
      <td>21.6</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4.03</td>
      <td>7.07</td>
      <td>0.469</td>
      <td>7.185</td>
      <td>34.7</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2.94</td>
      <td>2.18</td>
      <td>0.458</td>
      <td>6.998</td>
      <td>33.4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.33</td>
      <td>2.18</td>
      <td>0.458</td>
      <td>7.147</td>
      <td>36.2</td>
    </tr>
    <tr>
      <th>5</th>
      <td>5.21</td>
      <td>2.18</td>
      <td>0.458</td>
      <td>6.430</td>
      <td>28.7</td>
    </tr>
  </tbody>
</table>
</div>


<br>

```python
bost1.corr()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>LSTAT</th>
      <th>INDUS</th>
      <th>NOX</th>
      <th>RM</th>
      <th>MEDV</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>LSTAT</th>
      <td>1.000000</td>
      <td>0.603800</td>
      <td>0.590879</td>
      <td>-0.613808</td>
      <td>-0.737663</td>
    </tr>
    <tr>
      <th>INDUS</th>
      <td>0.603800</td>
      <td>1.000000</td>
      <td>0.763651</td>
      <td>-0.391676</td>
      <td>-0.483725</td>
    </tr>
    <tr>
      <th>NOX</th>
      <td>0.590879</td>
      <td>0.763651</td>
      <td>1.000000</td>
      <td>-0.302188</td>
      <td>-0.427321</td>
    </tr>
    <tr>
      <th>RM</th>
      <td>-0.613808</td>
      <td>-0.391676</td>
      <td>-0.302188</td>
      <td>1.000000</td>
      <td>0.695360</td>
    </tr>
    <tr>
      <th>MEDV</th>
      <td>-0.737663</td>
      <td>-0.483725</td>
      <td>-0.427321</td>
      <td>0.695360</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>


<br>

```python
plt.matshow(bost1.corr())
```




    <matplotlib.image.AxesImage at 0x7f324c1b6bd0>




![png]({{ site.baseurl }}/images/python_acorn/2017-06-10-acorn82_4_170306_files/2017-06-10-acorn82_4_170306_21_1.png)

<br>

```python
import seaborn as sns
```

<br>

```python
sns.heatmap(bost1.corr(), xticklabels=bost1.columns, yticklabels=bost1.columns)
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7f323bbb5dd0>




![png]({{ site.baseurl }}/images/python_acorn/2017-06-10-acorn82_4_170306_files/2017-06-10-acorn82_4_170306_23_1.png)  

<br>

LSTAT    % lower status of the population',  
INDUS    proportion of non-retail business acres per town',  
NOX      nitric oxides concentration (parts per 10 million)',  
RM       average number of rooms per dwelling',  
MEDV     Median value of owner-occupied homes in $1000's",  

<br>

## <font color='orange'> X = RM: 방의 갯수, y = MEDV: 집값  
## <font color='orange'> 데이터 분산도(산포도?)를 출력


```python
plt.scatter(bosto.RM, bosto.MEDV)
plt.xlabel('RM')
plt.ylabel('MEDV')
```




    <matplotlib.text.Text at 0x7f323b44e1d0>




![png]({{ site.baseurl }}/images/python_acorn/2017-06-10-acorn82_4_170306_files/2017-06-10-acorn82_4_170306_26_1.png)

<br>

## <font color='orange'> train data와 test데이터로 분리 (train_test_split 사용)

## <font color='orange'>  Linear Regression / Lasso / Ridge / elastic Net 방식으로 선형회귀 분석을 실시한 다음 계수를 출력하고 비교 그래프 출력

## <font color='orange'>  선형 회귀선을 출력

## <font color='orange'> Ridge 회귀 분석에서 적절한 alpha값을 결정

## <font color='orange'> 각 분석방법에 대하여 r2_score로 평가하고 mean_squared_error를 이용하여 MSE값을 출력


```python
# 데이터 표준화
from sklearn.preprocessing import StandardScaler
sc_x = StandardScaler()
sc_y = StandardScaler()

X_std = sc_x.fit_transform(X)
Y_std = sc_y.fit_transform(y)

# 모델 평가
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error
print 'MSE train: %.3f, test: %.3f' % (mean_squared_error(y_train, y_train_pred),
                                       mean_squared_error(y_test, y_test_pred))

print 'R^2 train: %.3f, test: %.3f' % (r2_score(y_train, y_train_pred),
                                       r2_score(y_test, y_test_pred))

from sklearn import linear_model
alphas = np.linspace(0, 20)
reg = linear_model.RidgeCV(alphas=alphas, store_cv_values=True, gcv_mode='eigen').fit(X_train, y_train)
```

<br>

```python
from sklearn.cross_validation import train_test_split
X = bosto.iloc[:, :-1].values
y = bosto['MEDV'].values
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)
slr = LinearRegression()
slr.fit(X_train, y_train)
y_train_pred = slr.predict(X_train)
y_test_pred = slr.predict(X_test)
plt.scatter(y_train_pred, y_train_pred - y_train,
           c='blue', marker='o', label='Training data')

plt.scatter(y_test_pred, y_test_pred - y_test,
           c='lightgreen', marker='s', label='Test data')
plt.xlabel('predicted values')
plt.ylabel('residuals')
plt.legend(loc='upper left')
plt.hlines(y=0, xmin=-10, xmax=50, lw=2, color='red')
plt.xlim([-10, 50])
plt.tight_layout()
plt.show()
```


![png]({{ site.baseurl }}/images/python_acorn/2017-06-10-acorn82_4_170306_files/2017-06-10-acorn82_4_170306_33_0.png)

<br>

```python
# 보간 다항식
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
X = np.array([258.0, 270.0, 294.0, 320.0,
              342.0, 368.0, 396.0, 446.0,
              480.0, 586.0])[:, np.newaxis]

y = np.array([236.4, 234.4, 252.8, 298.6,
              314.2, 342.2, 360.8, 368.0,
              391.2, 390.8])
lr = LinearRegression()
pr = LinearRegression()
quadratic = PolynomialFeatures(degree=2)
X_quad = quadratic.fit_transform(X)

lr.fit(X, y)
X_fit = np.arange(250, 600, 10)[:, np.newaxis]
y_lin_fit = lr.predict(X_fit)

pr.fit(X_quad, y)
y_quad_fit = pr.predict(quadratic.fit_transform(X_fit))

plt.scatter(X, y, label='training points')
plt.plot(X_fit, y_lin_fit, label='linear fit', linestyle='--')
plt.plot(X_fit, y_quad_fit, label='quadratic fit')
plt.legend(loc='upper left')
plt.show()
```


![png]({{ site.baseurl }}/images/python_acorn/2017-06-10-acorn82_4_170306_files/2017-06-10-acorn82_4_170306_34_0.png)
