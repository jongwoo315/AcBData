---
layout: post
title: Python - 17/03/06 (2)
category: acorn수업
---

# 회귀분석

---

원래 ipynb 제목
2. GLM.ipynb

<br>

## GLM

[scikit-learn, 1.1. Generalized Linear Models](http://scikit-learn.org/stable/modules/linear_model.html#stochastic-gradient-descent-sgd){:target="_blank"}
- 이상치
- 변수 간 종속성
-
- 위의 문제들을 해결하기 위한 방법들(가중치를 사용)
- logistic reg: 분류기(예측이 아님)
- lasso는 절대값으로

- ridge는 제곱값으로
    - RidgeCV: 데이터프레임을 몇 조각으로 나눠서 따로 확인
        - 데이터 양이 적을 때: 데이터 양을 늘리기 위한 방법
- elastic net은 절대값 + 제곱값 둘 다 사용

- LARS: 관측값에 비해 차원수가 많을 때
- OMP: 전진 선택법 / 노이즈가 있을 때 희소 signal을 찾을 때
- SGD: 하강 경사법
- 퍼셉트론: neural network
