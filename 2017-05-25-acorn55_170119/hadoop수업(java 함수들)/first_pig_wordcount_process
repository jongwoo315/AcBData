grunt> dump E;

pigstats.ScriptState - Pig features used in the script: GROUP_BY

hadoop.yarn.client.RMProxy - Connecting to ResourceManager at hadoopsvr/192.168.0.91:8032

pigstats.mapreduce.MRScriptState - Pig script settings are added to the job

mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.
mapReduceLayer.JobControlCompiler - Using reducer estimator: org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator

mapReduceLayer.InputSizeReducerEstimator - BytesPerReducer=1000000000 maxReducers=999 totalInputFileSize=1366

mapReduceLayer.JobControlCompiler - Added jar file:/home/hadoop/pig/pig-0.17.0-SNAPSHOT-core-h2.jar to DistributedCache through /tmp/temp1003314392/tmp153897618/pig-0.17.0-SNAPSHOT-core-h2.jar
mapReduceLayer.JobControlCompiler - Added jar file:/home/hadoop/pig/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1003314392/tmp-1473815846/automaton-1.11-8.jar
mapReduceLayer.JobControlCompiler - Added jar file:/home/hadoop/pig/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1003314392/tmp954599650/antlr-runtime-3.4.jar
mapReduceLayer.JobControlCompiler - Added jar file:/home/hadoop/pig/lib/joda-time-2.9.3.jar to DistributedCache through /tmp/temp1003314392/tmp1688888139/joda-time-2.9.3.jar

mapReduceLayer.JobControlCompiler - Setting up single store job


mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.

hadoop.yarn.client.RMProxy - Connecting to ResourceManager at hadoopsvr/192.168.0.91:8032

mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).

pig.builtin.PigStorage - Using PigTextInputFormat

mapreduce.lib.input.FileInputFormat - Total input paths to process : 1

pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1
pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1

mapreduce.JobSubmitter - number of splits:1
mapreduce.JobSubmitter - Submitting tokens for job: job_1484799674361_0032


hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1484799674361_0032

mapreduce.Job - The url to track the job: http://hadoopsvr:8088/proxy/application_1484799674361_0032/

mapReduceLayer.MapReduceLauncher - HadoopJobId: job_1484799674361_0032
mapReduceLayer.MapReduceLauncher - Processing aliases A,B,D,E
mapReduceLayer.MapReduceLauncher - detailed locations:    (매퍼) M: A[51,4],B[53,4],E[55,4],D[54,4] 
													   (컴바이너) C: E[55,4],D[54,4] 
													     (리듀서) R: E[55,4]

mapReduceLayer.MapReduceLauncher - 0% complete
mapReduceLayer.MapReduceLauncher - Running jobs are [job_1484799674361_0032]

mapReduceLayer.MapReduceLauncher - 50% complete
mapReduceLayer.MapReduceLauncher - Running jobs are [job_1484799674361_0032]
mapReduceLayer.MapReduceLauncher - Running jobs are [job_1484799674361_0032]

hadoop.yarn.client.RMProxy - Connecting to ResourceManager at hadoopsvr/192.168.0.91:8032
hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server

hadoop.yarn.client.RMProxy - Connecting to ResourceManager at hadoopsvr/192.168.0.91:8032
hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server

hadoop.yarn.client.RMProxy - Connecting to ResourceManager at hadoopsvr/192.168.0.91:8032
hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server

mapReduceLayer.MapReduceLauncher - 100% complete
